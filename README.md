<p align="center"> 
  <img src="marketing strategy.jpg" alt="Email Logo.png" width="800px" height="400px">
</p>
<h1 align="center"> Bank Marketing Effectiveness Prediction </h1>
<h3 align="center"> AlmaBetter Verfied Project - <a href="https://www.almabetter.com/"> AlmaBetter School </a> </h5>

<p align="center"> 
<img src="gif/spam detector.gif" alt="Animated gif pacman game" height="382px">
</p>

<p>Model predicts whether someone will make a deposit based on
the given attributes. I built five models using different
algorithms - Logistic Regression, Decision Tree, Random Forest,
Naive Bayes, and K-Nearest Neighbors. The hyperparameters will
then be tuned using GridSearch to optimise the model. Next step
will be to evaluate the metrics and compare each model to determine
which model is most effective.</p>

<h2> :floppy_disk: Project Files Description</h2>

<p>This Project includes 5 files as follows:</p>
<h4> Files:</h4>
<ul>
  <li><b>Bike_Sharing_Demand_Prediction_Capstone_Project.ipynb</b> - Includes all functions required for building classification model.</li>
  <li><b>bank-full.csv</b> - Input CSV file.</li>
  <li><b>PresentationPDF.pdf</b> - Powerpoint presentation on the summary of the project.</li>
  <li><b>Technical Documentation (1).pdf</b> - Detailed explanation of the approach of the project.</li>
  <li><b>ProjectSummary&TeamDetails.docx</b> - Project summary and the details on the challenges faced during the project. </li>
</ul


![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)

<h2> :book: Logistic Regression:</h2>

<p>Logistic regression, despite its name, is a classification model rather than regression model. Logistic regression is a simple and more efficient method for binary and linear classification problems. It is a classification model, which is very easy to realize and achieves very good performance with linearly separable classes. It is an extensively employed algorithm for classification in industry. The logistic regression model, is a statistical method for binary classification that can be generalized to multiclass classification. Scikit-learn has a highly optimized version of logistic regression implementation, which supports multiclass classification task </p>

<h2> :book: Decision Tree::</h2>

<p>Decision Tree is the most powerful and popular tool for classification and prediction. A Decision tree is a flowchart-like tree structure, where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label.</p>

<h2> :book: Random Forest:</h2>

<p>Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap and Aggregation, commonly known as bagging. The basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees.

Random Forest has multiple decision trees as base learning models. We randomly perform row sampling and feature sampling from the dataset forming sample datasets for every model. This part is called Bootstrap.</p>

<h2> :book: Decision Tree:</h2>

<p>Decision Tree is the most powerful and popular tool for classification and prediction. A Decision tree is a flowchart-like tree structure, where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label. </p>

<h2> :book: Random Forest:</h2>

<p>Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap and Aggregation, commonly known as bagging. The basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees.

Random Forest has multiple decision trees as base learning models. We randomly perform row sampling and feature sampling from the dataset forming sample datasets for every model. This part is called Bootstrap.</p>

<h2> :book: K Nearest Neighbor:</h2>

<p>K Nearest Neighbor algorithm falls under the Supervised Learning category and is used for classification (most commonly) and regression. It is a versatile algorithm also used for imputing missing values and resampling datasets. As the name (K Nearest Neighbor) suggests it considers K Nearest Neighbors (Data points) to predict the class or continuous value for the new Datapoint.

The algorithm’s learning is:

1. Instance-based learning: Here we do not learn weights from training data to predict output (as in model-based algorithms) but use entire training instances to predict output for unseen data.

2. Lazy Learning: Model is not learned using training data prior and the learning process is postponed to a time when prediction is requested on the new instance.

3. Non -Parametric: In KNN, there is no predefined form of the mapping function.</p>

<h2>Naive Bayes</h2>

<p>Naïve Bayes algorithm is a supervised learning algorithm, which is based on Bayes theorem and used for solving classification problems.
It is mainly used in text classification that includes a high-dimensional training dataset.
Naïve Bayes Classifier is one of the simple and most effective Classification algorithms which helps in building the fast machine learning models that can make quick predictions.
It is a probabilistic classifier, which means it predicts on the basis of the probability of an object.
Some popular examples of Naïve Bayes Algorithm are spam filtration, Sentimental analysis, and classifying articles.</p>


![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)

<!-- CREDITS -->
<h2 id="credits"> :scroll: Credits</h2>

< Bhavya > | Avid Learner | Data Scientist | Machine Learning Engineer | Deep Learning enthusiast

<p> <i> Contact me for Data Science Project Collaborations</i></p>


[![LinkedIn Badge](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/bhavya-reddy-sudo/)
[![GitHub Badge](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/bhavya-v-sudo/Bike-Sharing-Demand-Prediction)
[![Resume Badge](https://img.shields.io/badge/resume-0077B5?style=for-the-badge&logo=resume&logoColor=white)](https://drive.google.com/file/d/1Gw4yeLSWMvqIGMk0_zRv8CqwLk9lIIL9/view?usp=share_link)


![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)
<h2> :books: References</h2>
<ul>
  <li><p>ibm.com, 'ML | Logistic Regression'. [Online].</p>
      <p>Available: https://www.ibm.com/in-en/topics/logistic-regression</p>
  </li>
  <li><p>Youtube.com, 'Decision Tree'. [Online].</p>
      <p>Available: https://www.youtube.com/watch?v=_L39rN6gz7Y</p>
  </li>
  <li><p>javatpoint.com, 'Random forest algorithm'. [Online].</p>
      <p>Available: https://www.javatpoint.com/machine-learning-random-forest-algorithm</p>
  </li>
  <li><p>javatpoint.com, 'Naïve Bayes Classifier Algorithm'. [Online].</p>
      <p>Available:https://www.javatpoint.com/machine-learning-naive-bayes-classifier</p>
  </li>
</ul>

![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)

